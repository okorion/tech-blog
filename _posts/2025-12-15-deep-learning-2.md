---
title: "ANN 구현 실전: 데이터 준비 → 모델 설계 → 학습 → 평가 → 튜닝을 최소 반복으로 끝내기"
description: "데이터 누수 방지부터 평가·콜백·튜닝까지 ANN 구현 파이프라인을 안정적으로 돌리는 방법"
categories: ["🧬 Deep Learning"]
tags: [ANN, TrainingPipeline, Regularization, Evaluation]
image: /assets/posts/2025-12-15-deep-learning/image.jpg
date: 2025-12-15 21:51:00 +09:00
last_modified_at: 2025-12-15 21:51:00 +09:00
---

## TL;DR

* ANN 구현의 핵심은 **모델 구조가 아니라 파이프라인 안정성**이다.
* 데이터 누수, 불균형, 평가 지표 선택이 **성능의 70% 이상**을 좌우한다.
* Keras/TF2에서는 **훈련 루프를 단순화하고 콜백으로 제어**하는 것이 정석이다.
* Accuracy 하나만 보고 판단하면 **이탈 예측은 거의 항상 실패**한다.
* “안 되는 모델”의 대부분은 **학습률·스케일링·손실 설정 문제**다.
* 임계값(threshold)은 모델 성능이 아니라 **비즈니스 비용 함수**로 정한다.
* ANN은 고객 이탈 같은 **표(tabular) 데이터 문제에서 여전히 최우선 선택**이다.

---

## 전체 지도: ANN 구현은 딥러닝 전체에서 어디에 위치하는가

**한 문장 요약:** ANN 구현은 이후 모든 딥러닝 구현(CNN/RNN/AE)의 기준선이 된다.

딥러닝 구현 난이도를 “실무 관점”에서 보면 다음 순서다.

```
데이터 전처리/평가 설계 (가장 중요, 가장 어렵다)
 └─ ANN 구현 (기본기)
     ├─ CNN 구현 (구조만 추가)
     ├─ RNN 구현 (시간 축 관리 추가)
     └─ AutoEncoder/추천 (입력 구조 변경)
```

* ANN 구현을 제대로 하면:

  * CNN/RNN에서도 **학습/평가/디버깅 루틴을 그대로 재사용**할 수 있다.
* ANN 구현을 대충 하면:

  * 이후 모델은 “왜 안 되는지 모르는 상태”로 복잡해진다.

---

## 핵심 개념: ANN 구현에서 진짜 중요한 것은 무엇인가

### 1) “모델 구현”보다 “문제 정의”가 먼저다

**한 문장 요약:** ANN 성능은 코드보다 **데이터와 평가 설계**에서 결정된다.

* ANN 자체는 이미 충분히 강력하다.
* 성능 차이는 대부분:

  * 데이터 누수
  * 불균형
  * 잘못된 평가 지표
  * 임계값 설정
    에서 발생한다.

**미니 사례:**
고객 이탈 예측에서

* Accuracy 95% → 실제 이탈 고객은 거의 못 잡음
* 이유: 이탈 비율이 5%인데, “전부 안 떠난다”라고 해도 Accuracy는 높다.

---

## 작동 원리: ANN 구현 파이프라인 한 번에 보기

### 전체 흐름 (실무 기준)

```
데이터 로딩
 → 전처리(스케일링/인코딩)
 → Train/Val/Test 분리
 → 모델 정의
 → 컴파일(loss/optimizer/metrics)
 → 학습(fit + callbacks)
 → 평가(지표 + 임계값)
 → 튜닝/재학습
```

이 순서를 **깨뜨리지 않는 것**이 최소 반복의 핵심이다.

---

## 구현 체크리스트 (Keras / TF2 기준)

### 1) 데이터 준비

**한 문장 요약:** ANN 구현 실패의 절반은 데이터 단계에서 이미 결정된다.

* [ ] 타깃 불균형 확인 (이탈 문제의 기본)
* [ ] Train/Validation/Test **분리 먼저**
* [ ] 스케일링은 **Train 기준으로만 fit**
* [ ] 범주형 → One-hot / Embedding 여부 결정

**주의(데이터 누수):**
전체 데이터로 스케일러를 fit 하면
→ Validation/Test가 이미 미래 정보를 본다.

---

### 2) 모델 설계

**한 문장 요약:** 작게 시작해서 점진적으로 키운다.

```text
입력층
 → Dense(ReLU)
 → Dense(ReLU)
 → Dense(1, Sigmoid)
```

* 은닉층: ReLU
* 출력층:

  * 이진 분류 → Sigmoid
* 규칙:

  * 레이어 수보다 **과적합 여부**가 더 중요

**정규화 옵션**

* Dropout
* L2 Regularization

---

### 3) 컴파일: 손실·옵티마이저·지표

**한 문장 요약:** 손실은 학습을, 지표는 판단을 위해 존재한다.

```text
loss: BinaryCrossentropy
optimizer: Adam(lr=1e-3)
metrics: [AUC]
```

* loss ≠ metric
* metric은 여러 개 써도 되지만 **의사결정 기준은 1~2개로 고정**

---

### 4) 학습: 훈련 루프와 콜백 베스트 프랙티스

**한 문장 요약:** `fit()`은 단순하게, 제어는 콜백으로 한다.

#### 필수 콜백 3종

1. EarlyStopping

   * 기준: val_loss
   * patience: 3~5
   * restore_best_weights=True

2. ReduceLROnPlateau

   * 학습 정체 시 LR 감소

3. ModelCheckpoint

   * 최적 모델 저장

**이유:**

* 수동 튜닝보다 **자동 제어가 재현성과 효율이 높다**.

---

### 5) 평가: 지표 선택은 문제 정의다

#### 분류 지표 선택 가이드

| 지표      | 목적                  | 언제 쓰나     | 주의점                 |
| --------- | --------------------- | ------------- | ---------------------- |
| Accuracy  | 전체 정답 비율        | 클래스 균형   | 불균형에 취약          |
| Precision | 양성 예측 정확도      | 오탐 비용 큼  | 미탐 증가              |
| Recall    | 양성 탐지율           | 미탐 비용 큼  | 오탐 증가              |
| F1        | Precision-Recall 균형 | 일반적        | 비용 반영 한계         |
| AUC       | 순위 품질             | 불균형 데이터 | 임계값 직접 반영 안 됨 |

**이탈 예측 실무 기준**

* 학습/모델 비교: **AUC**
* 운영 의사결정: **Recall + 비용 기반 임계값**

---

## 실전 적용: 고객 이탈 예측에서 ANN을 어떻게 쓰는가

**한 문장 요약:** 이탈 예측은 “확률 문제”이자 “비용 최적화 문제”다.

### 핵심 포인트

* 모델 출력 = 이탈 확률
* 실제 행동 = 임계값 이상 고객에게 개입

### 임계값(threshold) 설정

* 0.5는 거의 항상 틀린 선택
* 기준:

  * 이탈 1명 놓쳤을 때 손실
  * 불필요한 개입 1건 비용

**미니 사례:**

* 이탈 고객 1명 손실 = 100
* 개입 비용 = 5
  → Recall을 더 중시, threshold를 낮춘다.

---

## 흔한 함정 TOP 7 + 해결책

1. **Accuracy만 보고 모델 채택**
   → 해결: AUC + Recall 필수

2. **데이터 누수(스케일링/분리 순서 오류)**
   → 해결: 분리 → 전처리 순서 고정

3. **불균형 데이터 무시**
   → 해결: class_weight 또는 resampling

4. **임계값을 0.5로 고정**
   → 해결: 비용 기반으로 결정

5. **과도한 모델 복잡도**
   → 해결: 베이스라인부터

6. **학습률 튜닝 없이 구조만 변경**
   → 해결: LR 먼저 조정

7. **Validation 없이 Test만 확인**
   → 해결: Val로 튜닝, Test는 최종 1회

---

## 미니 Q&A

1. **ANN으로 어디까지 커버 가능한가?**
   대부분의 표(tabular) 데이터 문제.

2. **레이어 수는 어떻게 정하나?**
   작게 시작 → 과적합 신호 보고 증가.

3. **Dropout은 언제 쓰나?**
   Train-Validation 성능 격차가 클 때.

4. **AUC가 높으면 좋은 모델인가?**
   순위는 좋다. 운영 성능은 임계값에 달렸다.

5. **CNN/RNN으로 바로 넘어가도 되나?**
   이 파이프라인이 익숙하면 가능하다.

---

## 다음 편 예고

다음 편에서는 **CNN 직관**으로 넘어간다.
ANN에서 배운 모든 학습·평가·디버깅 원칙은 그대로 유지된다.
달라지는 것은 오직 **입력 구조(이미지)와 연결 방식**뿐이다.

---

- 참고: [딥러닝의 모든 것 with Python, Tensorflow, Pytorch
](https://www.udemy.com/course/best-artificial-neural-networks/)
