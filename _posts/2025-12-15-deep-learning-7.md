---
title: "SOM으로 이상치·클러스터를 시각화해 사기 탐지로 연결하는 사고법"
description: "SOM으로 비지도 데이터 구조를 시각화하고 이상치·사기 탐지 후보를 좁히는 사고법 정리"
categories: ["🧬 Deep Learning"]
tags: [SOM, AnomalyDetection, Unsupervised, FraudDetection]
image: /assets/posts/2025-12-15-deep-learning/image.jpg
date: 2025-12-15 21:56:00 +09:00
last_modified_at: 2025-12-15 21:56:00 +09:00
---

## TL;DR

* SOM(Self-Organizing Map)은 **라벨 없이 데이터 구조를 시각화**하는 데 특화된 비지도 학습이다.
* 사기 탐지에서 SOM의 가치는 **정답 예측이 아니라 “의심 지점 후보를 좁히는 것”**이다.
* SOM 결과는 **라벨이 아니라 지도(map)**다. 해석 없이는 바로 쓰면 안 된다.
* K-Means와 달리 SOM은 **연속적인 지형(Topology)**을 제공해 **경계·이상치**를 읽기 쉽다.
* 운영에서는 **알람 임계값, 오탐/미탐 비용**이 모델 성능보다 중요하다.
* 비지도 결과를 지도학습처럼 쓰는 순간, 시스템은 망가진다.
* SOM은 **탐색→가설 생성→운영 규칙 설계**의 도구다.

---

## 전체 지도: SOM은 딥러닝/ML 전체에서 어디에 위치하는가

**한 문장 요약:** SOM은 “예측 모델”이 아니라 **데이터 구조를 드러내는 탐색 도구**다.

모델 역할 기준으로 보면 다음과 같다.

```
지도학습 (ANN/CNN/RNN)
 └─ 예측/분류/회귀

비지도학습
 ├─ K-Means: 군집 나누기
 ├─ PCA/AE: 차원 축소
 └─ SOM: 구조 시각화 + 이상치 탐색
```

* SOM은 **사기 탐지, 이상치 탐색, 데이터 이해 단계**에서 빛난다.
* “사기 여부를 맞춘다”보다
  “조사할 대상을 어디서부터 볼 것인가”에 답한다.

---

## 핵심 개념: 왜 SOM이 필요한가, 무엇인가

### 1) 사기 탐지의 현실

**한 문장 요약:** 사기 데이터는 대부분 **라벨이 없거나, 불완전**하다.

* 실제 환경:

  * 사기 라벨은 사후 확정
  * 정상 데이터 압도적으로 많음
* 문제:

  * 지도학습으로 바로 가기 어렵다.
  * 패턴을 “먼저 발견”해야 한다.

**미니 사례:**
금융 거래 로그에서

* 수백만 건 중 사기는 수십 건
  → “정답 예측”보다 **의심 구간 압축**이 먼저다.

---

### 2) SOM(Self-Organizing Map)이란

**한 문장 요약:** SOM은 고차원 데이터를 **2차원 격자(map)** 위에 구조를 보존하며 배치한다.

* 정의:

  * 입력 벡터들을
  * 유사한 것끼리
  * 가까운 노드에 배치
* 핵심 속성:

  * **Topology Preservation**
    (가까운 데이터는 지도에서도 가깝다)

**비유:**
SOM은 “도시 지도”다.
비슷한 가게는 같은 동네에 몰리고,
특이한 가게는 외곽에 떨어진다.

---

## SOM vs K-Means (반드시 구분)

**한 문장 요약:** K-Means는 “나누기”, SOM은 “지형 만들기”다.

| 구분      | SOM                      | K-Means     |
| --------- | ------------------------ | ----------- |
| 목적      | 구조 시각화, 이상치 탐색 | 군집 분할   |
| 출력      | 2D 지도(연속 구조)       | 군집 ID     |
| 해석      | 이웃 관계·경계·외곽      | 군집 중심   |
| 제약      | 해석 필요, 정답 없음     | K 사전 지정 |
| 사기 탐지 | 탐색·후보 추출에 적합    | 후처리 용도 |

**중요:**

* SOM 결과는 **“이 데이터는 사기다”가 아니다.**
* **“이 데이터는 다른 것들과 다르다”**에 가깝다.

---

## 작동 원리: SOM은 어떻게 동작하고 학습하는가

### 1) 입력→출력 흐름

**한 문장 요약:** SOM은 입력을 “가장 비슷한 노드(BMU)”에 매핑한다.

```
입력 벡터 x
 → 모든 노드와 거리 계산
 → Best Matching Unit(BMU) 선택
 → BMU와 이웃 노드 가중치 갱신
```

* BMU: 현재 입력과 가장 유사한 노드
* 이웃 노드: BMU 주변 격자

---

### 2) 학습 흐름

**한 문장 요약:** 학습은 “지도 전체를 조금씩 입력 쪽으로 당기는 과정”이다.

* 초기:

  * 노드 가중치 랜덤
* 반복:

  * 입력이 오면
  * BMU + 이웃 노드가 입력 쪽으로 이동
* 결과:

  * 데이터 분포를 반영한 2D 지도 완성

**직관:**
고무판 위에 자석(데이터)을 하나씩 올리면,
가장 가까운 점과 주변이 같이 끌려간다.

---

## 구현 체크리스트 (SOM 실전 기준)

### 데이터

* [ ] 스케일링 필수 (거리 기반 모델)
* [ ] 의미 없는 피처 제거
* [ ] 이상치 제거 여부는 사전 결정

### 모델

* [ ] 격자 크기 결정(너무 작으면 정보 손실)
* [ ] 거리 함수(Euclidean 기본)
* [ ] 학습률/이웃 반경 점진 감소

### 학습

* [ ] 충분한 반복 횟수
* [ ] 수렴 여부 시각적으로 점검

### 평가

* [ ] 지도 시각화(U-Matrix 등)
* [ ] 외곽/경계 노드 집중 관찰

### 디버깅

* [ ] 모든 데이터가 한 곳에 몰리지 않는지
* [ ] 스케일링 누락 여부
* [ ] 격자 크기 과소 설정 여부

---

## 실전 적용: 사기 탐지로 연결하는 법

### 1) SOM 결과 해석 절차

**한 문장 요약:** SOM은 “결과”가 아니라 **출발점**이다.

1. 밀집 영역 확인 → 정상 패턴
2. 경계/외곽 영역 확인 → 이상 후보
3. 해당 영역 데이터 샘플링
4. 도메인 룰/추가 분석 연결

---

### 2) 운영 관점: 알람 설계

**한 문장 요약:** 운영의 핵심은 “임계값과 비용”이다.

* 알람 기준 예시:

  * 특정 노드의 평균 거리 초과
  * 외곽 노드 매핑 비율
* 비용 고려:

  * 오탐(불필요 조사 비용)
  * 미탐(사기 손실)

**실무 포인트:**

* SOM은 **후보 수를 줄이는 필터**
* 최종 판단은:

  * 규칙
  * 추가 모델
  * 사람 검증
    과 결합해야 한다.

---

## 흔한 함정 TOP 7 + 해결책

1. **(함정 1순위) SOM 결과를 라벨로 착각**
   → 해결: SOM은 탐색 도구임을 명확히 정의

2. **비지도 결과를 바로 자동 차단에 연결**
   → 해결: 반드시 인간 검증 단계 포함

3. **스케일링 없이 학습**
   → 해결: 거리 기반 모델은 스케일이 전부다

4. **격자 크기 너무 작게 설정**
   → 해결: 데이터 다양성에 맞게 확장

5. **K-Means와 동일하게 해석**
   → 해결: SOM은 지형, K-Means는 분할

6. **도메인 지식 없이 해석**
   → 해결: 특징·규칙과 반드시 결합

7. **운영 비용 무시**
   → 해결: 알람은 기술 문제가 아니라 비용 문제

---

## 미니 Q&A

1. **SOM으로 사기를 자동 분류할 수 있나?**
   아니다. 후보 탐색용이다.

2. **K-Means보다 항상 좋은가?**
   목적이 다르다. 구조 이해는 SOM이 유리하다.

3. **격자 크기는 어떻게 정하나?**
   데이터 수·다양성 기준으로 점진 실험.

4. **라벨이 일부라도 있으면?**
   SOM으로 탐색 후 지도학습으로 연결.

5. **실무에서 아직 쓰이나?**
   사기·이상치 탐색 단계에서는 여전히 유효하다.

---

## 다음 편 예고

다음 편에서는 **Boltzmann Machine과 추천 시스템**으로 넘어간다.
SOM이 “구조를 보는 눈”이었다면,
다음은 **확률적으로 선호를 복원하는 사고 전환**이다.

---

- 참고: [딥러닝의 모든 것 with Python, Tensorflow, Pytorch
](https://www.udemy.com/course/best-artificial-neural-networks/)
