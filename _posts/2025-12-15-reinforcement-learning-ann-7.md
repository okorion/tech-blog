---
title: "LLM 구현 핵심만 정리: 트랜스포머 → SFT/LoRA/QLoRA → 의료 챗봇 → RAG → Agentic AI"
description: "트랜스포머부터 SFT·LoRA/QLoRA·RAG·Agentic AI까지 제품화 중심 LLM 구조를 한눈에 정리"
categories: ["🔁 Reinforcement Learning & ANN"]
tags: [LLM, RAG, FineTuning, AgenticAI]
image: /assets/posts/2025-12-15-reinforcement-learning-ann/image.jpg
date: 2025-12-15 21:46:00 +09:00
last_modified_at: 2025-12-15 21:46:00 +09:00
---

## 이 글의 목적

**핵심 요약**

* 이 파트의 목표는 “거대한 LLM 이론”이 아니라 **작동하는 제품 구조**다.
* 트랜스포머는 *다음 토큰 예측기*, 나머지는 **운영을 가능하게 하는 기술**이다.
* 미세조정(SFT)·RAG·RL은 서로 대체가 아니라 **역할 분담**이다.
* 최종 그림은 **LLM 단독이 아닌 Agent 시스템**이다.

**예시**

* 의료 챗봇: LLM + RAG + 출력 제한
* 업무 자동화: LLM + 도구 호출 + RL 피드백

---

## 1. 트랜스포머 직관: 다음 토큰 예측 + 어텐션

### 정의

* 트랜스포머는 “지금까지의 토큰을 보고 **다음 토큰 확률 분포**를 예측”하는 모델이다.

**핵심 요약**

* LLM의 본질은 **언어 이해가 아니라 확률 예측**이다.
* 어텐션은 “어디를 봐야 할지”를 결정하는 가중치다.
* 복잡한 구조보다 **동작 원리**를 이해하는 게 중요하다.

**직관**

```text
입력 문장 → 중요한 단어에 더 집중 → 다음 단어 확률 계산
```

**구현 포인트**

* 모든 추론/학습은 “다음 토큰 예측”으로 환원된다.

---

## 2. 컨텍스트 윈도우: 제품 설계의 가장 큰 제약

**정의**

* 컨텍스트 윈도우는 **한 번에 모델이 볼 수 있는 토큰 길이**다.

**핵심 요약**

* 윈도우는 비용·지연·환각을 동시에 좌우한다.
* 무조건 크게 넣는다고 품질이 오르지 않는다.
* 이 한계 때문에 **RAG와 요약 전략**이 필수다.

### 실무 영향

| 항목          | 영향                         |
| ------------- | ---------------------------- |
| 비용          | 토큰 수에 비례               |
| Latency       | 길수록 느림                  |
| Hallucination | 관련 없는 토큰 많을수록 증가 |

**예시**

* 긴 의료 기록을 그대로 넣으면 오히려 진단 품질 하락

---

## 3. SFTTrainer 흐름: 미세조정의 실제 과정

### 정의

* **SFT(Supervised Fine-Tuning)** 는 지시–응답 데이터로 LLM을 재학습한다.

**핵심 요약**

* 데이터 품질이 모델 크기보다 중요하다.
* 파이프라인을 이해하지 못하면 디버깅이 불가능하다.
* 대부분의 실패는 **데이터/토크나이징 단계**에서 발생한다.

### SFTTrainer 파이프라인

```text
데이터 준비
 → 토크나이징
 → 학습 인수 설정
 → 훈련
 → 추론 검증
```

### SFT 파이프라인 체크리스트

| 단계       | 입력       | 출력        | 성공 기준      |
| ---------- | ---------- | ----------- | -------------- |
| 데이터     | Q/A 텍스트 | 정제된 샘플 | 일관성         |
| 토크나이징 | 텍스트     | 토큰        | 길이 분포 안정 |
| 학습       | 토큰       | 체크포인트  | loss 감소      |
| 추론       | 프롬프트   | 응답        | 도메인 적합    |

---

## 4. LoRA / QLoRA: 미세조정의 현실적 선택

### 정의

* **LoRA**: 일부 저차원 가중치만 학습
* **QLoRA**: 가중치를 양자화하여 메모리 절감

**핵심 요약**

* Full FT는 비용·메모리 측면에서 비현실적이다.
* LoRA는 “충분히 좋은 품질 + 빠른 반복”을 제공한다.
* QLoRA는 단일 GPU에서도 대형 모델을 가능하게 한다.

### LoRA vs Full Fine-Tuning

| 항목      | Full FT | LoRA/QLoRA |
| --------- | ------- | ---------- |
| 메모리    | 매우 큼 | 작음       |
| 학습 속도 | 느림    | 빠름       |
| 품질      | 최고    | 실무 충분  |
| 배포      | 어려움  | 용이       |

**트레이드오프**

* 메모리 ↓ → 접근성 ↑ → 반복 속도 ↑

---

## 5. RAG: 지식 주입을 위한 구조적 해법

### 정의

* **RAG(Retrieval-Augmented Generation)** 는 외부 지식을 검색해 LLM 입력에 주입한다.

**핵심 요약**

* RAG는 “기억력 확장 장치”다.
* 모델을 다시 학습시키지 않고 지식을 바꿀 수 있다.
* 품질의 대부분은 **검색과 분할(chunking)** 에서 결정된다.

### RAG 설계 파라미터

| 파라미터   | 권장 범위 | 의미        |
| ---------- | --------- | ----------- |
| chunk size | 300–800   | 의미 단위   |
| overlap    | 10–20%    | 문맥 연결   |
| top-k      | 3–8       | 검색 다양성 |
| rerank     | 사용 권장 | 품질 향상   |

**실패 케이스**

* 검색 결과 부정확 → 환각
* chunk 너무 큼/작음 → 맥락 손실
* 프롬프트가 검색 결과를 무시

---

## 6. 의료 챗봇: 안전·검증 관점

**핵심 요약**

* 의료 도메인은 “정확성”보다 **안전성**이 우선이다.
* LLM은 조언자가 아니라 **정보 보조 도구**여야 한다.

### 필수 안전 장치

| 항목         | 내용           |
| ------------ | -------------- |
| 출력 제한    | 진단/처방 금지 |
| 근거 제시    | 출처 문서 인용 |
| 로그         | 질문/응답 기록 |
| 에스컬레이션 | 전문가 연결    |

**성공 기준**

* 잘 모를 때 “모른다”고 말하는가
* 근거 없는 단정이 없는가

---

## 7. RL + LLM = Agentic AI

### 정의

* **Agent** 는 LLM이 계획을 세우고, 도구를 사용하며, 결과로부터 피드백을 받는 구조다.

**핵심 요약**

* LLM은 두뇌, RL은 **행동 평가 메커니즘**이다.
* 계획 → 실행 → 피드백 루프가 핵심이다.
* 단순 챗봇과 Agent의 차이는 **행동과 학습**이다.

### Agent 구조 (텍스트 다이어그램)

```text
User Goal
  ↓
LLM (계획/추론)
  ↓
Tool/API/Env 실행
  ↓
결과 관측
  ↓
RL 기반 피드백/조정
```

**어디에 쓰이나**

* 자동화 워크플로
* 게임·시뮬레이션 에이전트
* 운영 최적화

---

## 흔히 하는 오해 3가지와 교정

**오해 1**: “LLM은 크면 다 해결된다”
→ **교정**: 구조 없이는 비용만 늘어난다.

**오해 2**: “RAG면 환각이 사라진다”
→ **교정**: 검색 품질이 나쁘면 오히려 악화된다.

**오해 3**: “Agent는 프롬프트 기술이다”
→ **교정**: 피드백 루프가 없는 Agent는 자동완성이다.

---

## 핵심 체크리스트 (재학습용)

* [ ] 트랜스포머를 다음 토큰 예측기로 설명할 수 있는가
* [ ] 컨텍스트 윈도우 제약을 제품 관점에서 이해했는가
* [ ] SFT 파이프라인을 단계별로 설명할 수 있는가
* [ ] LoRA/QLoRA의 트레이드오프를 아는가
* [ ] RAG 설계 파라미터를 조정해본 적이 있는가
* [ ] 의료 챗봇에서 안전 장치를 설계했는가
* [ ] LLM과 RL의 역할 차이를 구분하는가

---

## 한 줄 요약

**실무 LLM은 모델이 아니라, 미세조정·RAG·RL이 결합된 ‘구조물’이다.**

---

- 참고: [ AI 만들기 2025: 강화학습과 인공신경망 완전정복, Agentic AI, Gen AI, RL
](https://www.udemy.com/course/best-ai-17-hours/)
