---
title: "CNN 이미지 분류와 SageMaker Autopilot 한 번에 정리하기"
description: "SageMaker에서 CNN 학습·배포 흐름과 Autopilot의 자동 모델 탐색 과정을 한 번에 정리한 실전 복습 노트"
categories: ["🤖 AWS Sagemaker"]
tags: [CNN, AutoML, SageMaker, 배포]
image: /assets/posts/2025-12-12-sagemaker/image.png
date: 2025-12-12 17:59:00 +09:00
last_modified_at: 2025-12-12 17:59:00 +09:00
---

# CNN 이미지 분류와 SageMaker Autopilot 한 번에 정리하기

이 글은 Udemy 강의 후반부의 **프로젝트 #5(CNN 이미지 분류)**와 **프로젝트 #6(SageMaker Studio & Autopilot)**을 한 편으로 통합한 실전 복습 노트다.
딥러닝 아키텍처 자체보다, **SageMaker에서 CNN을 어떻게 학습·배포하는지**, 그리고 **AutoML(AutoPilot)이 어떤 방식으로 모델을 자동 생성하는지**에 초점을 맞춘다.
강의 후반부의 흐름(이미지 → 딥러닝 → AutoML)을 이어서 보면, SageMaker 기반 ML 파이프라인의 전체 지도가 한눈에 잡힌다.

### 이번 글 핵심 요약 4~6줄

* CNN은 **Conv → Pool → FC** 구조로 이미지의 공간적 패턴(엣지·윤곽·질감)을 추출한다.
* SageMaker에서 이미지 모델을 학습할 때는 **S3 업로드 → Training Job 실행 → Endpoint 배포** 흐름이 기본이다.
* Autopilot은 **EDA → 피처 파이프라인 조합 → 후보 모델 탐색 → Best Model 도출**을 자동 수행한다.
* AutoML은 “빠른 baseline 필요할 때”, CNN은 “명확한 도메인 구조가 있을 때” 각각 강력하다.
* 두 기능 모두 SageMaker의 핵심 워크플로우(Tuning, Endpoint, Experiment Tracking)를 재사용한다.

---

## CNN 핵심 구조와 직관

CNN은 이미지를 “픽셀 행렬”이 아니라, **특징(feature) 지도가 흐르는 계층 구조**로 해석한다.
완전연결(MLP)이 모든 픽셀을 일렬로 펴서 처리한다면, CNN은 **공간 구조를 보존**하면서 학습해 이미지에 최적화되어 있다.

### CNN 계층 흐름(개념 그림 수준 텍스트 버전)

```
입력(32x32 이미지)
   ↓
Conv(필터로 엣지/선/기초 패턴 추출)
   ↓
Activation(ReLU로 비선형성 부여)
   ↓
Pooling(특징 압축, 위치 변화에 견고해짐)
   ↓
Conv + Pool 반복(더 복잡한 형태 검출)
   ↓
Flatten(1D로 변환)
   ↓
Fully Connected(클래스별 확률 산출)
```

### CNN이 이미지에서 강한 이유

* 지역 정보(패치 단위)를 활용
* 필터 공유로 파라미터 감소
* 계층이 깊어질수록 추상적 패턴 학습(바퀴 → 자동차 윤곽 등)

강의에서는 LeNet 계열과 유사한 구조로, **작은 이미지(교통 표지판)**를 처리하는 데 적합한 경량 CNN을 사용했다.

---

### 실무 적용 시 고려 질문

* 입력 이미지 크기와 비율은 통일되어 있는가?
* 클래스 개수가 많을수록 Conv 층 깊이를 늘릴 필요가 있는가?

---

## SageMaker에서 CNN 모델 학습하기

CNN을 SageMaker에서 학습할 때 핵심은 **학습 스크립트(entry point)**를 실행 가능한 형태로 패키징하고, 데이터는 S3에 올린 뒤 학습 Job에 전달하는 것이다.

### 전체 흐름 요약

```
[1] 로컬에서 이미지 확인/라벨 검증
[2] S3 버킷에 훈련·검증 이미지 업로드
[3] 학습 스크립트(entry_point.py) 작성
[4] Estimator 정의 (TensorFlow / PyTorch)
[5] Training Job 실행
[6] 모델 아티팩트 자동 저장 (S3)
[7] Endpoint 배포 → 실시간 예측
```

### Estimator + 학습 스크립트 패턴 예시

```python
from sagemaker.tensorflow import TensorFlow

estimator = TensorFlow(
    entry_point="train.py",      # CNN 학습 코드
    role=role,
    framework_version="2.3",
    py_version="py37",
    instance_type="ml.p2.xlarge",   # GPU 인스턴스
    instance_count=1,
    hyperparameters={
        "epochs": 10,
        "batch_size": 64,
        "learning_rate": 0.001
    }
)

estimator.fit({"train": train_s3, "validation": val_s3})
```

### 학습 스크립트에서 중요한 부분

* `model = build_cnn()`
* `model.fit(train_ds, validation_data=val_ds, epochs=args.epochs)`
* 체크포인트 및 최종 모델을 `/opt/ml/model/`에 저장해야 SageMaker가 모델을 인식한다.

### Endpoint 배포 패턴

```python
predictor = estimator.deploy(
    initial_instance_count=1,
    instance_type="ml.m5.large"
)
```

---

### 실무 적용 시 고려 질문

* GPU 인스턴스 비용을 어떻게 관리할 것인가?
* 학습 스크립트의 출력을 S3 어디에 저장할지 명확히 했는가?

---

## 모델 평가와 에러 분석(이미지 분류 관점)

이미지 분류에서 중요한 것은 **어떤 클래스에서 오분류가 발생하는지**를 정확히 보는 것이다.
이때 가장 유용한 도구가 **혼동 행렬(confusion matrix)**이다.

### 혼동 행렬 활용 예

* 특정 표지판끼리 형태가 비슷해 혼동되는지 확인
* 데이터 수가 부족한 클래스 식별
* 모델의 약점을 구체적으로 파악해 augmentation 전략 도출

### 이미지 분류에서 중요한 분석 포인트

* **클래스 불균형**: 적은 데이터 → 오분류 증가
* **Top-1 vs Top-k Accuracy**:

  * Top-1: 가장 확률 높은 클래스가 정답
  * Top-k: k개 중 하나라도 정답이면 인정 → 서비스 도메인에 따라 중요
* **Confident Wrong Prediction**: 높은 확률로 틀린 경우는 위험(의료/자율주행 등)

---

### 실무 적용 시 고려 질문

* 데이터가 어떤 클래스에서 부족한가? 증강이 필요한가?
* Top-k를 활용할 도메인인지? (예: 검색·추천 시스템)

---

## SageMaker Autopilot: AutoML이 하는 일

Autopilot은 “구조화 데이터를 기반으로 자동으로 최적 모델을 탐색하는 시스템”이다.
CNN처럼 모델을 직접 설계해야 하는 이미지 문제와 달리, **데이터 테이블만 넣으면 전체 ML 파이프라인을 자동 생성**한다.

### Autopilot의 3단계

1. **자동 데이터 분석(EDA)**

   * 타입 감지, 결측치 처리, 스케일링 여부 판단
2. **후보 모델/파이프라인 탐색**

   * XGBoost, Linear, Tree 계열 등 다양한 알고리즘 자동 시험
3. **Best Model 선정 + 배포 옵션 제공**

   * Endpoint 자동 생성 가능
   * Notebook 형태로 “어떻게 만들었는지”까지 설명 제공

### 강의의 보험료 예측 예시와 연결

* 입력: S3에 업로드한 CSV, 타깃 컬럼
* Autopilot 수행:

  * 전처리 자동 생성
  * 파라미터 튜닝
  * 여러 모델 조합 시험
* 사용자가 할 일:

  * 데이터 준비 + 실행 옵션 설정
  * 최종 모델 선택 후 배포

---

### 실무 적용 시 고려 질문

* AutoML이 만든 파이프라인을 그대로 사용할 것인가?
* 자동 선택된 모델의 해석 가능성이 도메인에 적합한가?

---

## AutoML 도입 vs 직접 설계: 의사결정 기준

다음은 AutoML(Autopilot)을 사용할지, CNN/XGBoost 등을 직접 설계할지를 선택하는 기준이다.

### AutoML이 유리한 상황

* 빠르게 baseline이 필요함
* 구조화 데이터(표 형태)로 문제 정의됨
* 피처 수 많고 상호작용이 복잡하지만 규칙 기반 튜닝 시간이 부족
* 실험 시간 대비 효율 극대화가 필요

### 직접 설계가 필요한 상황

* 이미지/텍스트 등 딥러닝 필요
* 커스텀 전처리(도메인 규칙) 반드시 필요
* 모델 해석력 중요
* 지표 최적화 기준이 비표준(예: 비용 기반 custom loss)

### AutoML vs 직접 설계 비교표

| 기준        | AutoML(Autopilot)                    | 직접 모델 설계(CNN/XGB 등) |
| ----------- | ------------------------------------ | -------------------------- |
| 속도        | 매우 빠름                            | 느림(설계+튜닝 필요)       |
| 통제력      | 낮음                                 | 매우 높음                  |
| 성능        | 중상급(문제에 따라 최고 나오기도 함) | 최적화 시 최고 성능 가능   |
| 도메인 특화 | 약함                                 | 강함                       |
| 유지보수    | 자동화 쉬움                          | 직접 관리 필요             |

---

### 실무 적용 시 고려 질문

* baseline만 필요한가, 아니면 최고 성능이 필요한가?
* 모델의 해석 가능성이 중요한 도메인인가?

---

## 딥러닝 + AutoML을 SageMaker에서 함께 사용할 때의 큰 그림

CNN은 **이미지·시각 패턴이 핵심인 문제**에 적합하고, Autopilot은 **구조화 데이터 기반 문제 자동화**에 적합하다.
강의 후반부에서 두 프로젝트를 연이어 다루는 이유는 다음과 같다.

1. SageMaker가 **딥러닝·전통 ML·AutoML을 모두 동일한 구조(S3 → Training → Model → Endpoint)** 아래에서 구동한다는 점
2. 사용자는 “어떤 모델을 선택하든” SageMaker의 워크플로우 패턴만 이해하면 확장 가능
3. 이미지 문제(CNN)와 구조화 문제(AutoML) 모두 프로덕션 배포까지 연결할 수 있다는 점

### 다시 볼 때 빠르게 잡히는 요약(4~6줄)

* 이미지 모델이 필요하면: **데이터 정리 → S3 업로드 → CNN 학습 스크립트 작성 → Training Job → Endpoint**
* 구조화 데이터 모델이 필요하면: **Autopilot으로 baseline 생성 → 필요하면 XGBoost 등 직접 튜닝**
* 두 방식 모두 **SageMaker의 공통 구조(Estimator/Tuner/Endpoint)**를 재사용
* CNN은 통제력·성능 극대화에, Autopilot은 빠른 탐색과 자동화를 위한 선택지
* 강의 전체 흐름은 “전처리 → 모델 선택 → 튜닝 → 배포”라는 하나의 공통 프레임을 다루는 과정
* 실무에서는 CNN과 AutoML을 문제 유형에 따라 혼합적으로 사용하면 개발 속도와 성능 균형을 잡을 수 있다.

---

### 실무 적용 시 고려 질문

* CNN 기반 이미지 모델이 필요한가, 아니면 구조화 데이터 모델이 필요한가?
* baseline 자동 탐색(AutoML)과 수동 모델 설계 중 어떤 전략이 현재 프로젝트에 더 적합한가?

---

- 참고: [초보자를 위한 AWS SageMaker 실습 | 6개 프로젝트 구축하기
](https://www.udemy.com/course/best-aws-sagemaker/learn/lecture/29630912?start=15#overview)
