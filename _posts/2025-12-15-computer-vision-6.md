---
title: "생성 모델을 한 장의 프레임으로 이해하기"
description: "오토인코더·DeepDream/Style·GAN까지 생성 모델을 표현 학습 관점에서 한눈에 정리"
categories: ["🥽 Computer Vision"]
tags: [GenerativeModel, Autoencoder, GAN, Representation]
image: /assets/posts/2025-12-15-computer-vision/image.jpg
date: 2025-12-15 23:20:00 +09:00
last_modified_at: 2025-12-15 23:20:00 +09:00
---
## 문제 정의

**생성 모델**은 “무엇인가를 맞히는 것”이 아니라 **데이터가 어떻게 생겼는지의 구조를 학습**해 새로운 샘플을 만들거나 변형하는 문제다.
핵심은 결과 이미지가 아니라 **내부 표현(representation)** 이다.

**요약 한 줄**
생성 모델은 그림을 그리는 기술이 아니라 **데이터 분포를 이해하는 방법**이다.

---

## 1) 오토인코더(AE): 목적은 압축이 아니라 표현 학습

### 정의

오토인코더는 입력을 **잠재 표현(latent)** 으로 인코딩했다가 다시 복원하는 신경망이다.

### 직관

* 인코더: “이 이미지를 설명하는 최소한의 좌표”
* 디코더: “그 좌표로 원본을 재구성”

압축은 결과일 뿐, 진짜 목적은 **의미 있는 내부 표현**을 얻는 것이다.

### 오해 포인트

* 오토인코더 = 이미지 압축기
  → 실제 가치는 **특징 학습**과 **이상치 탐지**에 있다.

### 언제 쓰는가 / 쓰지 말아야 하는가

* ✔ 차원 축소, 이상 탐지, 사전학습
* ✘ 고품질 이미지 생성 목적 단독 사용

### 구현 체크리스트

* 병목(latent) 크기 명확화
* 재구성 손실만 과도하게 줄이지 않기

### 요약

AE는 “잘 그리는 법”이 아니라 **잘 표현하는 법**을 배운다.

**세 문장 요약 (AE)**

1. AE는 입력을 의미 있는 좌표로 바꾼다.
2. 복원 성능은 표현 품질의 간접 지표다.
3. 생성보다는 표현 학습에 강하다.

---

## 2) 선형 vs 합성곱 오토인코더

### 정의

* **선형 AE**: Flatten → Dense
* **합성곱 AE**: Conv → Pool / Deconv

### 직관

선형 AE는 이미지를 **숫자 나열**로 본다.
합성곱 AE는 **공간 구조를 유지한 채** 요약한다.

### 오해 포인트

* 선형 AE도 충분히 쓸 수 있다
  → 이미지에서는 **공간 정보 손실**이 치명적이다.

### 언제 쓰는가 / 쓰지 말아야 하는가

* 합성곱 AE: 이미지/영상
* 선형 AE: 저차원 벡터 데이터

### 요약

이미지라면 합성곱 AE가 **기본 선택**이다.

---

## 3) DeepDream & Style Transfer: 입력을 최적화한다

### 정의

* **DeepDream**: 특정 뉴런 활성화를 최대화하도록 **입력을 수정**
* **Style Transfer**: 내용/스타일 손실을 기준으로 **입력을 업데이트**

### 직관

가중치는 고정되어 있다.
“무엇을 그릴지”가 아니라 **“입력을 어떻게 바꿀지”를 학습**한다.

### 오해 포인트

* 모델을 다시 학습한다
  → 실제로는 **경사 상승으로 이미지 자체를 수정**

### 언제 쓰는가 / 쓰지 말아야 하는가

* ✔ 시각화, 예술적 변형
* ✘ 실시간 생성 파이프라인

### 요약

이 둘은 생성 모델이라기보다 **시각화 기법**에 가깝다.

**세 문장 요약 (DeepDream/Style)**

1. 가중치는 고정, 입력만 바뀐다.
2. 손실 정의가 결과를 결정한다.
3. 생성보다 해석·표현에 가깝다.

---

## 4) GAN: 두 모델의 게임

### 정의

GAN은 **생성자(G)** 와 **구분자(D)** 가 경쟁하며 학습하는 구조다.

### 직관

* G: 가짜 이미지를 점점 진짜처럼 만든다
* D: 진짜/가짜를 구분하려 한다
  → 둘의 균형점이 데이터 분포 근사

### 학습 불안정의 원인

* **모드 붕괴**: 특정 유형만 생성
* 손실 불균형: 한쪽이 너무 강해짐

### 오해 포인트 (교정)

* GAN = 항상 고품질 이미지 ❌
* 학습만 오래 하면 해결 ❌

### 언제 쓰는가 / 쓰지 말아야 하는가

* ✔ 데이터 증강, 이미지 생성
* ✘ 안정성 최우선 서비스

### 요약

GAN은 강력하지만 **운영 난이도가 높다**.

**세 문장 요약 (GAN)**

1. GAN은 게임 이론 구조다.
2. 균형이 깨지면 학습이 망가진다.
3. 품질보다 안정성이 더 어렵다.

---

## 5) 실무에서 어디에 쓰이는가

* **데이터 증강**: 학습 데이터 부족 보완
* **압축/복원**: AE 기반 전처리
* **이미지 편집**: 스타일/속성 변환
* **생성**: 콘텐츠 제작, 시뮬레이션

핵심은 “단독 제품”보다 **보조 모듈**로 쓰인다는 점이다.

---

## 핵심 스니펫 (합성곱 오토인코더 구조)

```python
# Encoder
x = Conv2D(32, 3, activation='relu', padding='same')(inputs)
x = MaxPooling2D(2)(x)
latent = Conv2D(64, 3, activation='relu', padding='same')(x)

# Decoder
x = Conv2DTranspose(32, 3, activation='relu', padding='same')(latent)
x = UpSampling2D(2)(x)
outputs = Conv2D(3, 3, activation='sigmoid', padding='same')(x)
```

**주의**

* latent 크기가 표현력을 결정
* 복원 손실만 보지 말 것

---

## 최종 요약

* AE는 표현 학습 도구
* 합성곱 AE가 이미지 기본값
* DeepDream/Style은 입력 최적화
* GAN은 강력하지만 불안정
* 생성 모델은 **보조 수단**으로 가치가 크다

---

## 다음 액션 플랜 (5줄)

1. 합성곱 오토인코더로 표현을 시각화한다
2. latent 크기 변화에 따른 복원 품질을 본다
3. GAN을 데이터 증강 용도로 제한 적용한다
4. 생성 품질보다 안정성을 우선한다
5. 다음 단계로 세그멘테이션/YOLO와 결합을 검토한다

---

- 참고: [Computer Vision (컴퓨터 비전) : 마스터 클래스
](https://www.udemy.com/course/best-computer-vision/)