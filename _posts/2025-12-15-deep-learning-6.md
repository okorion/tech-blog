---
title: "RNN 구현 실전: 윈도잉, 정규화, 학습·평가, 롤링 예측까지"
description: "윈도잉·정규화·롤링 평가로 시계열 RNN을 안전하게 구현하는 데이터 설계 중심 가이드"
categories: ["🧬 Deep Learning"]
tags: [RNN, TimeSeries, Windowing, Evaluation]
image: /assets/posts/2025-12-15-deep-learning/image.jpg
date: 2025-12-15 21:55:00 +09:00
last_modified_at: 2025-12-15 21:55:00 +09:00
---

## TL;DR

* RNN/LSTM 구현의 성패는 **모델 코드가 아니라 데이터 구성(윈도잉·누수 방지)** 에서 갈린다.
* 시계열에서는 **train/val 분리 → 스케일링 → 윈도잉** 순서를 절대 바꾸지 마라.
* 윈도우 길이·예측 지평·stride는 **도메인 가설 + 검증 비용**으로 결정한다.
* MSE 하나로 평가를 끝내면 주가 예측은 거의 항상 실패한다.
* **방향성·리스크 관점의 보조 지표**를 반드시 함께 본다.
* 학습이 불안정하면 구조를 바꾸기 전에 **gradient clipping → LR → batch size** 순으로 점검한다.
* RNN 구현은 “예측 문제”라기보다 **검증 설계 문제**다.

---

## 전체 지도: RNN 구현은 딥러닝에서 어디에 위치하는가

**한 문장 요약:** RNN 구현은 “ANN/CNN 구현 감각 + 시계열 전용 데이터 규율”이 결합된 단계다.

구현 난이도 기준 흐름:

```
ANN 구현 (기본 학습/평가 루틴)
 └─ CNN 구현 (데이터 증강/과적합 제어)
     └─ RNN 구현 (시간 축, 누수 방지, 롤링 평가)
```

* ANN/CNN과 달리 RNN은:

  * **데이터 분리/전처리 순서가 바뀌는 순간 의미가 붕괴**한다.
* 따라서 RNN 구현은 “코드 실력”보다 **데이터 사고력**을 시험한다.

---

## 핵심 개념: RNN 구현에서 진짜 중요한 것

### 1) 윈도잉(Windowing)

**한 문장 요약:** 윈도잉은 “과거 N개로 미래를 예측한다”는 가정을 데이터로 구현하는 과정이다.

* 시계열은 그대로 모델에 넣을 수 없다.
* 반드시 `(과거 구간 → 미래 타깃)` 쌍으로 잘라야 한다.

```
[t-10, t-9, ..., t-1] → y_t
```

**미니 사례:**
주가 예측에서 “최근 20일 가격으로 다음 날 종가 예측”
→ window size = 20, horizon = 1

---

### 2) 정규화(Normalization)

**한 문장 요약:** 정규화는 “미래를 보지 않고 스케일을 맞추는 기술”이다.

* 반드시:

  1. 시간 기준으로 train/val/test 분리
  2. **train 데이터로만 scaler.fit**
  3. 나머지는 transform만 수행

**오해/함정:**
전체 데이터로 스케일링
→ 모델은 이미 “미래 분포”를 본 상태가 된다.

---

### 3) 예측 지평(Horizon)

**한 문장 요약:** horizon은 “얼마나 먼 미래를 맞추려는가”에 대한 선언이다.

* horizon = 1: 다음 시점
* horizon > 1: 멀티스텝 예측

**직관:**
horizon이 길수록:

* 문제 난이도 ↑
* 신호 대비 노이즈 ↑
* 평가 신뢰도 ↓

---

## 작동 원리: 입력→출력 흐름, 학습 흐름

### 1) 입력→출력(Forward)

**한 문장 요약:** RNN은 윈도우 단위 시퀀스를 한 타임스텝씩 처리한다.

```
X: (batch, window, feature)
 → RNN/LSTM
 → 마지막 hidden state
 → Dense
 → 예측값
```

* many-to-one 구조가 주가 예측의 기본
* 입력은 “과거 묶음”, 출력은 “미래 한 점(또는 몇 점)”

---

### 2) 학습(Training)

**한 문장 요약:** 학습은 “시간을 펼친 네트워크”에서 오차를 줄이는 과정이다.

* BPTT(Backpropagation Through Time)
* 시계열이 길수록:

  * 기울기 폭주/소실 위험 증가
  * 학습 불안정성 증가

→ 안정화 기법이 필수로 등장한다.

---

## 구현 체크리스트 (RNN/LSTM 실전)

### 데이터 (⚠️ 최우선)

**한 문장 요약:** 데이터 설계가 잘못되면, 어떤 모델도 의미 없다.

* [ ] 시간 기준 train/val/test 분리
* [ ] train 기준 스케일링
* [ ] 윈도우에 미래 정보 포함 여부 수동 검증
* [ ] 랜덤 셔플 금지

---

### 윈도잉 파라미터 의사결정 규칙

| 항목        | 의미             | 선택 규칙                    |
| ----------- | ---------------- | ---------------------------- |
| Window size | 과거 기억 길이   | 도메인 주기 1~2배            |
| Horizon     | 예측 거리        | 짧을수록 안정                |
| Stride      | 윈도우 이동 간격 | 1이 기본, 데이터 많으면 증가 |

**실무 감각 예시(주가):**

* 단기 트레이딩 → window 10~30, horizon 1
* 중기 추세 → window 60~120, horizon 1~5

---

### 모델

* [ ] LSTM 또는 GRU 선택
* [ ] hidden size 과도하지 않게
* [ ] 출력 구조(one-to-one vs many-to-one) 명확화

---

### 학습

* [ ] EarlyStopping 필수
* [ ] Gradient Clipping 적용
* [ ] 작은 learning rate부터 시작

---

### 평가

* [ ] 시간 순 평가 유지
* [ ] 롤링(워크포워드) 검증

---

### 디버깅

* [ ] 예측이 평균으로 수렴하는지
* [ ] train/val 분포 차이
* [ ] loss 폭주 여부

---

## 평가를 “MSE 이후”로 확장하기

### 왜 MSE만으로는 부족한가

**한 문장 요약:** 주가 예측은 “값 맞추기”보다 “방향/리스크 관리” 문제다.

* MSE가 낮아도:

  * 방향을 자주 틀리면 실전 가치 없음
* MSE는:

  * 큰 오차에 민감
  * 방향 정보 반영 못 함

---

### 보조 지표 아이디어 (방향성/리스크)

| 지표               | 의미                  | 언제 유용       |
| ------------------ | --------------------- | --------------- |
| Direction Accuracy | 상승/하락 맞춘 비율   | 매매 판단       |
| Hit Ratio          | 임계 수익률 초과 비율 | 전략 평가       |
| Max Drawdown       | 최대 손실             | 리스크 관리     |
| Sharpe-like        | 변동 대비 수익        | 포트폴리오 관점 |

**미니 사례:**
MSE는 약간 나쁘지만
방향 정확도 + 누적 수익이 더 좋은 모델
→ 실전에서는 후자가 낫다.

---

## 학습 불안정 시 튜닝 우선순위

**한 문장 요약:** 구조를 바꾸기 전에 “안정화 레버”부터 당겨라.

### 1순위: Gradient Clipping

* 폭주 방지
* 거의 부작용 없음

### 2순위: Learning Rate

* 너무 크면 발산
* 너무 작으면 학습 정체

### 3순위: Batch Size

* 작을수록 노이즈 ↑
* 클수록 안정, 하지만 일반화 ↓

### 4순위: 모델 구조

* 레이어 수/hidden size 조정은 마지막

---

## 실전 적용: 주가 예측에서 RNN 구현의 현실

**한 문장 요약:** 주가 예측은 “미래를 맞춘다”기보다 “잘못된 확신을 줄인다”.

* 비즈니스 관점:

  * 절대 가격 예측 → 위험
  * 방향/확률 기반 의사결정 → 현실적
* 리스크:

  * 과거 패턴 붕괴
  * 데이터 누수 착각
* 운영 포인트:

  * 주기적 재학습
  * 성능 하락 감지 기준 필요

---

## 흔한 함정 TOP 7 + 해결책

1. **랜덤 셔플로 데이터 분리**
   → 해결: 시간 순 분리 고정

2. **전체 데이터로 스케일링**
   → 해결: train 기준 fit

3. **윈도우에 미래 포함**
   → 해결: 인덱스 수동 점검

4. **MSE 하나로 모델 선택**
   → 해결: 방향/리스크 지표 병행

5. **LSTM이면 다 해결된다고 착각**
   → 해결: 데이터/검증 먼저

6. **시퀀스 길이 무작정 증가**
   → 해결: 짧은 window부터

7. **검증 성능을 실전 성능으로 착각**
   → 해결: 롤링 평가 필수

---

## 미니 Q&A

1. **Window size는 클수록 좋은가?**
   아니다. 노이즈만 늘어날 수 있다.

2. **Horizon을 길게 잡으면?**
   난이도와 불확실성이 급증한다.

3. **RNN이 항상 LSTM보다 나쁜가?**
   실무에서는 거의 그렇다.

4. **주가 예측에 정말 쓸 수 있나?**
   단독 예측보다 의사결정 보조에 적합하다.

5. **CNN/Transformer로 대체해야 하나?**
   문제에 따라 다르다. RNN은 여전히 단순·해석 친화적이다.

---

## 다음 편 예고

다음 편에서는 **SOM(자기조직화 지도)** 로 넘어간다.
이번 편이 “시간 의존성”을 다뤘다면, 다음은 **라벨 없는 데이터에서 구조를 읽는 법**이다.
사기 탐지·이상치 문제로 사고 전환이 일어난다.

---

- 참고: [딥러닝의 모든 것 with Python, Tensorflow, Pytorch
](https://www.udemy.com/course/best-artificial-neural-networks/)
