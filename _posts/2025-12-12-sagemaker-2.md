---
title: "데이터 엔지니어링과 ML 기본기 한 번에 복습하기"
description: "데이터 전처리부터 편향·분산, 정규화, 평가 지표, S3/EC2/IAM/SageMaker Studio까지 ML 파이프라인 기초를 한 번에 복습하는 요약 노트"
categories: ["🤖 AWS Sagemaker"]
tags: [AWS, 데이터전처리, ML기초, SageMaker]
image: /assets/posts/2025-12-12-sagemaker/image.png
date: 2025-12-12 17:55:00 +09:00
last_modified_at: 2025-12-12 17:55:00 +09:00
---

이 글은 **Udemy 강의에 흩어져 있던 데이터 전처리·ML 기본 개념·AWS 기초 서비스**를 한 번에 묶어 정리한 요약 노트다.
모델 실습을 시작하기 전에 “기초 개념을 빠르게 리프레시”하는 용도로 설계했으며, 강의 이론 파트를 매번 처음부터 다시 보지 않아도 되도록 구성했다.

현업 ML 파이프라인을 구성하려면 “데이터 처리 → 모델 선택 → 평가 → 배포” 흐름이 명확해야 한다. 이 글은 그중 **데이터 처리·모델 개념·기초 평가 지표·AWS 기반 환경 이해**를 압축적으로 복습한다.

### 이번 글 핵심 키워드

* 결측치 처리
* 범주형 인코딩(라벨/원핫)
* 스케일링(표준화·정규화)
* 피처 엔지니어링
* 편향/분산
* L1/L2 정규화
* 과적합/과소적합
* PCA(차원 축소)
* RMSE, MAE, R²
* Precision/Recall/F1, ROC-AUC
* S3, EC2, IAM, SageMaker Studio

---

## 데이터 전처리 핵심 패턴

전처리는 “모델에 넣기 전에 데이터를 모델이 이해 가능한 형태로 만드는 과정”이다.
비유하면 요리 재료 손질에 해당한다. 손질이 엉망이면 아무리 좋은 레시피(모델)를 써도 맛이 없다.

---

### 1) 결측치 처리(Missing Values)

#### 언제 문제가 되는가?

* 센서 데이터 누락, 수기 입력 오류, 크롤링 중 일부 값이 없음 등
* 대부분의 ML 알고리즘(XGBoost 제외)에서 결측치는 학습 불가

#### 대표적 처리법

* **삭제**: 결측치가 매우 적고 패턴이 없을 때
* **대치(Imputation)**: 평균/중앙값/최빈값, 혹은 간단한 모델 기반 대치
* **특별 값으로 채우기**: 0 또는 "unknown"과 같이 별도 카테고리 생성

#### 실무용 의사코드

```python
df = df.fillna(df.mean())      # 수치형 평균 대치
df = df.fillna("unknown")      # 범주형 결측치 처리
```

---

### 2) 범주형 변수 인코딩(Categorical Encoding)

#### 언제 문제가 되는가?

* 문자열 형태의 데이터(도시명, 보험등급 등)를 모델이 숫자로만 처리할 수 있기 때문
* 선형 모델은 범주 간 거리 개념이 없기 때문에 잘못된 인코딩은 성능 저하로 이어짐

#### 대표적 처리법

* **Label Encoding**: 순서가 있거나 카테고리가 많은 경우
* **One-Hot Encoding**: 일반적인 범주형
* **Target Encoding**: 고카디널리티(수천 개)에서 자주 사용

#### 의사코드

```python
df = pd.get_dummies(df, columns=['city'])
```

---

### 3) 스케일링 / 정규화(Scaling / Normalization)

#### 언제 문제가 되는가?

* 피처 간 크기 차이가 큰 경우(키 170 vs 연봉 5,000,000)
* 거리 기반 모델(KNN)이나 경사하강 기반 모델(선형 회귀, 로지스틱 등)의 성능에 큰 영향

#### 대표적 처리법

* **표준화(Standardization)**: 평균 0, 표준편차 1
* **정규화(Min-Max Scaling)**: 0~1 범위로 스케일링

#### 의사코드

```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)
```

---

### 4) 피처 엔지니어링(Feature Engineering)

#### 언제 문제가 되는가?

* 기존 피처만으로는 모델이 충분한 패턴을 찾기 어려울 때
* 실제 업무에서는 “피처가 곧 성능”이다.

#### 대표적 처리법

* **피처 조합**: A×B, A/B, 로그 변환 등
* **날짜 피처 분해**: 년/월/일/요일/근무일 여부 등
* **구간화(Binning)**: 연속형을 범주형으로 변환

#### 의사코드

```python
df['income_per_age'] = df['income'] / df['age']
df['log_income'] = np.log1p(df['income'])
```

---

### 스스로 점검 질문

* 숫자형/범주형/결측 데이터를 각각 어떤 방식으로 처리해야 하는지 말할 수 있는가?
* 스케일링이 “왜 필요한지”를 단순 암기 아닌 직관으로 설명할 수 있는가?

---

## ML 기본 개념 정리: 편향·분산·정규화·과적합

ML의 성능을 결정하는 본질 요소는 **편향(Bias)**, **분산(Variance)**, **정규화(Regularization)**다.
비유하면, 모델은 “패턴을 찾는 학생”이고 데이터는 “연습 문제집”이다.

---

### 편향(Bias) vs 분산(Variance)

* **편향**: 모델이 너무 단순해서 복잡한 패턴을 못 잡음 → *언더피팅*
* **분산**: 모델이 너무 예민해서 데이터의 잡음까지 학습 → *오버피팅*

직관적 비유:

* 편향이 크면 “문제를 건성으로 풀고 틀리는 학생”
* 분산이 크면 “푸는 문제마다 풀이 방식이 달라지는 학생”

---

### L1 vs L2 정규화

정규화는 “과적합을 방지하기 위해 모델의 복잡도를 억제하는 규제 장치”다.

| 항목      | L1 (Lasso)                                    | L2 (Ridge)                       |
| --------- | --------------------------------------------- | -------------------------------- |
| 패널티    | 가중치 절댓값                                 | 가중치 제곱                      |
| 특징      | 일부 가중치를 0으로 만듦 → **특징 선택 효과** | 가중치를 균등하게 줄여 안정적    |
| 사용 상황 | 피처가 많고 불필요한 게 섞여 있을 때          | 대부분의 회귀 문제에서 기본 선택 |

---

### 과적합 / 과소적합

* **과적합**: 학습 데이터에만 지나치게 맞춰진 상태

  * 그래프 비유: 데이터 점을 지그재그로 정확히 따라가는 선
* **과소적합**: 모델이 너무 단순하여 패턴을 잡지 못한 상태

  * 그래프 비유: 모든 점을 직선 하나로 설명하려 하는 경우

---

### 강의와 연결

* **회귀 파트**: 편향/분산 개념 이해 필수
* **XGBoost**: L1/L2 규제 포함 → 모델 튜닝 시 중요한 요소
* **PCA**: 분산(variance)을 기준으로 축을 줄이는 개념과 직접 연결됨

---

### 스스로 점검 질문

* L1이 왜 피처 선택 효과를 가지는가?
* 과적합을 확인하고 해결하는 방법을 최소 2가지 이상 말할 수 있는가?

---

## 평가 지표 총정리: 회귀 vs 분류

평가 지표는 “모델이 얼마나 잘했는지”를 숫자로 표현한다.
데이터 유형에 따라 지표의 의미가 크게 달라진다.

---

### 회귀 지표

| 지표            | 정의                  | 언제 유용한가           | 강의 등장      |
| --------------- | --------------------- | ----------------------- | -------------- |
| **MSE**         | 오차 제곱 평균        | 큰 오차에 민감          | 선형 회귀      |
| **RMSE**        | MSE의 제곱근          | 직관적(원 단위 유지)    | 선형 회귀      |
| **MAE**         | 절대 오차 평균        | 이상치 영향 최소화      | 회귀 실습      |
| **MAPE**        | 실제값 대비 오차 비율 | 비율 해석이 중요할 때   | 실무 응용 사례 |
| **R²**          | 설명력(0~1)           | 모델이 설명한 변동 비율 | 기본 회귀      |
| **Adjusted R²** | 피처 수 보정한 R²     | 피처가 많을 때          | 고급 회귀      |

현업 팁:

* 오차의 “절대 크기”가 중요하면 RMSE/MAE
* 피처가 많고 모델 비교가 목적이면 R²/Adjusted R²

---

### 분류 지표

| 지표          | 정의                             | 사용 상황                               | 강의 등장 |
| ------------- | -------------------------------- | --------------------------------------- | --------- |
| **Accuracy**  | 전체 중 맞춘 비율                | 클래스 불균형 없을 때                   | 기본 분류 |
| **Precision** | 예측한 Positive 중 실제 Positive | 금융·의료 false positive 비용 높을 때   | XGBoost   |
| **Recall**    | 실제 Positive 중 맞춘 비율       | 의료·안전 분야 false negative 방지 필요 | 건강 예측 |
| **F1-score**  | Precision·Recall 조화 평균       | 불균형 데이터에서 균형 평가             | 분류 전반 |
| **ROC-AUC**   | 분류 성능의 전체적 면적          | 임계값 무관 평가                        | 고급 분류 |

현업 팁:

* 비대칭 위험이 있을 땐 Accuracy는 거의 의미 없음
* 의료 예측 문제에서는 **Recall 또는 F1** 우선
* 대규모 서비스에서는 ROC-AUC로 전반적 성능 비교

---

### 스스로 점검 질문

* Precision과 Recall을 직관적으로 구분해 설명할 수 있는가?
* 회귀 문제에서 RMSE vs MAE를 선택하는 기준이 무엇인가?

---

## PCA 직관과 쓰임새

PCA는 **고차원 데이터를 “정보 손실을 최소화하며” 더 적은 차원으로 압축하는 기술**이다.
비유하면 “여러 각도에서 찍은 사진을 가장 정보가 많은 방향으로 눌러 평면에 투영하는 것”과 같다.

---

### 핵심 직관

* 데이터의 “분산(흩어진 정도)”이 가장 큰 축을 1번 주성분으로 선택
* 그 다음 큰 축을 2번 주성분으로 선택
* 이렇게 축을 재정렬해 차원을 줄임

수학적으로는 고유값/고유벡터를 사용하지만, 실무에서는
“데이터가 가장 활발히 변하는 방향을 고르는 과정” 정도만 이해하면 충분하다.

---

### 왜 필요한가?

* 차원이 너무 높으면 모델 학습이 느려지고 과적합 위험 증가
* 시각화(2D/3D) 필요 시 유용
* 불필요한 잡음을 제거하는 효과

---

### 강의와 연결

* 심혈관 질환 예측 프로젝트에서 **고차원 피처 정리** 목적으로 등장
* XGBoost 이전에 차원을 줄여 데이터 품질 개선에 활용

---

### 스스로 점검 질문

* PCA는 정보를 “없애는” 기술인가 “압축하는” 기술인가?
* PCA를 적용하면 모델 성능이 반드시 좋아지는가?

---

## AWS 기초 서비스: S3, EC2, IAM, SageMaker Studio

강의에서 가장 많이 등장하는 AWS 구성요소 4개를 정리한다.

---

### S3

* **강의 내 사용**: 데이터 파일, 전처리 결과, 모델 아티팩트 저장소
* **주의점**: 잘못된 IAM 권한 또는 공개 설정으로 인한 보안 사고가 가장 흔함

### EC2

* **강의 내 사용**: AWS 기본 컴퓨팅 개념 소개용, 로컬 개발 확장
* **주의점**: 인스턴스 종료를 잊으면 과금 발생

### IAM

* **강의 내 사용**: SageMaker Execution Role을 통해 S3 접근
* **주의점**: 과도한 권한 부여(AdministratorAccess)는 금물

### SageMaker Studio

* **강의 내 사용**: Notebook에서 데이터 탐색·학습·실험 관리
* **주의점**: Studio 인스턴스도 실시간 과금 → 종료 습관 필요

---

## 이 글을 기반으로 강의 실습 들어가기 전에 볼 체크리스트

* 결측치/범주형/스케일링 처리 방식을 구분해 말할 수 있는가
* 편향·분산·정규화(L1/L2) 개념을 그림 없이 설명할 수 있는가
* 회귀/분류 지표의 차이와 실무 선택 기준을 알고 있는가
* PCA가 필요한 상황과 효과를 말할 수 있는가
* S3, IAM Role, Studio의 역할을 각각 명확히 분리할 수 있는가
* 전처리 → 모델 → 평가 → 배포 흐름이 머릿속에서 그려지는가
* Endpoint 비용이 학습 비용보다 높을 수 있다는 사실을 기억하는가

---

- 참고: [초보자를 위한 AWS SageMaker 실습 | 6개 프로젝트 구축하기
](https://www.udemy.com/course/best-aws-sagemaker/learn/lecture/29630912?start=15#overview)
